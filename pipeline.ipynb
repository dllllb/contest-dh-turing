{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run freq_ngrams.py\n",
    "%run -n metric.py\n",
    "%run utils.py\n",
    "%run pipeline.py\n",
    "%run w2v_features.py\n",
    "%run features.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# days 24-27 was avalilable for training\n",
    "# day 28 and final holdout was not avalilable\n",
    "train_files = [\n",
    "    'datasets/train_20170724.json', \n",
    "    'datasets/train_20170725.json',\n",
    "    'datasets/train_20170726.json',\n",
    "    'datasets/train_20170727.json'\n",
    "]\n",
    "dialogs = []\n",
    "for path in train_files:\n",
    "    with open(path) as f:\n",
    "        dialogs += json.load(f)\n",
    "\n",
    "data_tr, target_tr = dialogs_preproc(dialogs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_files = [\n",
    "    'datasets/train_final.json'\n",
    "]\n",
    "dialogs = []\n",
    "for path in test_files:\n",
    "    with open(path) as f:\n",
    "        dialogs += json.load(f)\n",
    "\n",
    "data_tst, target_tst = dialogs_preproc(dialogs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "extractors = [\n",
    "    min_len, max_len, avg_len,\n",
    "    min_words, max_words, avg_words,\n",
    "    min_QRatio, max_QRatio, avg_QRatio,\n",
    "    min_WRatio, max_WRatio, avg_WRatio,\n",
    "    ngram_intersection,\n",
    "    get_human_words(), get_human_words_norm(), get_bot_words(), get_bot_words_norm(),\n",
    "    get_stop_words_share(),\n",
    "    min_partial_ratio, max_partial_ratio, avg_partial_ratio,\n",
    "    dialogue_len, dialog_len_share, max_in_row,\n",
    "    started_dialogue, finished_dialogue,\n",
    "    get_words_not_in_w2v(),\n",
    "    min_reply_time, avg_reply_time,\n",
    "    two_phrases_in_a_row, capital_letters_ratio, question_marks, has_a_question, punctuation_marks,\n",
    "]\n",
    "\n",
    "tr1 = DataFrameFeatureUnion([\n",
    "    simple_transfromer(extractors),\n",
    "    PCAWordFeatures(side='user1'),\n",
    "    PCAWordFeatures(side='user2'),\n",
    "    PCACharFeatures(side='user1'),\n",
    "    PCACharFeatures(side='user2'),\n",
    "    FreqNgrams(ngram_len=2),\n",
    "    FreqNgrams(ngram_len=3),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 6s, sys: 1.82 s, total: 3min 8s\n",
      "Wall time: 3min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "features_tr = tr1.fit_transform(data_tr)\n",
    "features_tst = tr1.transform(data_tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.59198789016217235"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "m = RandomForestRegressor(n_estimators=200, max_depth=6, min_samples_leaf=5)\n",
    "m.fit(features_tr, target_tr)\n",
    "\n",
    "spearman_scorer(m, features_tst, target_tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module '_catboost' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.69830802084401244"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "\n",
    "m = CatBoostRegressor()\n",
    "m.fit(features_tr, target_tr)\n",
    "\n",
    "spearman_scorer(m, features_tst, target_tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module '_catboost' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.72215377711892592"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "\n",
    "m = CatBoostRegressor(loss_function='Poisson')\n",
    "m.fit(features_tr, target_tr)\n",
    "\n",
    "spearman_scorer(m, features_tst, target_tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.70423843038732781"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "m = XGBRegressor(n_estimators=500, max_depth=3, learning_rate=0.03, objective='count:poisson')\n",
    "m.fit(features_tr, target_tr)\n",
    "\n",
    "spearman_scorer(m, features_tst, target_tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.67469713219748628"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "m = LGBMRegressor(n_estimators=500, max_depth=3, learning_rate=0.03, objective='poisson')\n",
    "m.fit(features_tr, target_tr)\n",
    "\n",
    "spearman_scorer(m, features_tst, target_tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def prepare_pairs(features, target):\n",
    "    slices_x, slices_y = [], []\n",
    "    for e in features.index:\n",
    "        _features = features.drop(e, axis=0)\n",
    "        _target = target.drop(e, axis=0)\n",
    "        row = features.loc[e]\n",
    "        row_y = target.loc[e]\n",
    "        sample_x, _x, sample_y, _y = train_test_split(\n",
    "            _features,\n",
    "            _target,\n",
    "            train_size=100,\n",
    "            stratify=_target)\n",
    "        sample_x = sample_x.copy()\n",
    "        for col, val in row.items():\n",
    "            sample_x['sample_{}'.format(col)] = val\n",
    "        sample_dialog_id, sample_id = e\n",
    "        sample_x['sample_dialog_id'] = sample_dialog_id\n",
    "        sample_x['sample_id'] = sample_id\n",
    "        sample_x = sample_x.reset_index().set_index(['dialogId', 'Id', 'sample_dialog_id', 'sample_id'])\n",
    "        slices_x.append(sample_x)\n",
    "\n",
    "        sample_y = sample_y.copy().to_frame()\n",
    "        sample_y['sample_dialog_id'] = sample_dialog_id\n",
    "        sample_y['sample_id'] = sample_id\n",
    "        sample_y = sample_y.reset_index().set_index(['dialogId', 'Id', 'sample_dialog_id', 'sample_id']).squeeze()\n",
    "        slices_y.append(sample_y < row_y)\n",
    "\n",
    "    pairs = pd.concat(slices_x)\n",
    "    pairs_y = pd.concat(slices_y)\n",
    "    return pairs, pairs_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 56s, sys: 7.16 s, total: 4min 3s\n",
      "Wall time: 4min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pairs_x, pairs_y = prepare_pairs(features_tr, target_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', colsample_bytree=1, learning_rate=0.03,\n",
       "        max_bin=255, max_depth=3, min_child_samples=10, min_child_weight=5,\n",
       "        min_split_gain=0, n_estimators=500, nthread=-1, num_leaves=31,\n",
       "        objective='binary', reg_alpha=0, reg_lambda=0, seed=0, silent=True,\n",
       "        subsample=1, subsample_for_bin=50000, subsample_freq=1)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "m = LGBMClassifier(n_estimators=500, max_depth=3, learning_rate=0.03)\n",
    "m.fit(pairs_x, pairs_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 9s, sys: 2.99 s, total: 2min 12s\n",
      "Wall time: 2min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pairs_tst, pairs_tst_y = prepare_pairs(features_tst, target_tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73324411074387852"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = m.predict_proba(pairs_tst)\n",
    "\n",
    "dialogue_preds = pd.Series(preds[:,1], index=pairs_tst.index, name='scores')\n",
    "dialogue_preds = dialogue_preds.to_frame().reset_index()[['sample_dialog_id', 'sample_id', 'scores']]\n",
    "\n",
    "scores = dialogue_preds.groupby(['sample_dialog_id', 'sample_id']).sum()\n",
    "\n",
    "pred_true_df = pd.DataFrame({'target': target_tst, 'rank': scores.scores})\n",
    "\n",
    "spearman(pred_true_df.target, pred_true_df['rank'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
